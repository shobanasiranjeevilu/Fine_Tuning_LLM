{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate,FewShotChatMessagePromptTemplate\n",
    "from utils import read_notebook, format_for_gpt, extract_cells, create_prompt_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_1,human_feedback_example_1 = create_prompt_example(path_to_example=\"\",human_grade=\"\",human_feedback=\"\")\n",
    "example_2,human_feedback_example_2 = create_prompt_example(path_to_example=\"\",human_grade=\"\",human_feedback=\"\")\n",
    "example_3,human_feedback_example_3 = create_prompt_example(path_to_example=\"\",human_grade=\"\",human_feedback=\"\")\n",
    "\n",
    "\n",
    "examples = [\n",
    "    {\"input\": example_1, \"output\": human_feedback_example_1},\n",
    "    {\"input\": example_2, \"output\": human_feedback_example_2},\n",
    "    {'input': example_3, \"output\": human_feedback_example_3}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"user\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    \n",
    "    input_variables=[\"input\"],\n",
    "    examples=examples,\n",
    "    example_prompt= example_prompt\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OpenAI_api_key = \"\"\n",
    "\n",
    "if OpenAI_api_key == \"\":\n",
    "    print(\"please provide your openAI api key\")\n",
    "chat_model = ChatOpenAI(temperature=0, model_name=\"gpt-4\", openai_api_key=OpenAI_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant that evaluate programming assignments and check all the instructions are followed and grade it from 1-100 and provide Feedback what went wrong.Provide Reasoning on why you gave such grade. \\\n",
    "            Given the dataset about weather in Australia , predict rain using models. \\\n",
    "         - must have used ML model to perform prediction. \\\n",
    "          - Include VectorAssembler successfully to perform feature transformation  \"\n",
    "),\n",
    "        \n",
    "        few_shot_prompt,\n",
    "        (\"user\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "chain = final_prompt | chat_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'path to inference notebook folder'\n",
    "file_names,files = [],[]\n",
    "# Collecting .ipynb files and avoiding hidden/system files\n",
    "for file in os.listdir(folder_path):\n",
    "    full_path = os.path.join(folder_path, file)\n",
    "    if os.path.isfile(full_path) and file.endswith('.ipynb') and not file.startswith('.'):\n",
    "        file_names.append(full_path)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### To avoid RateLimitException taking 3 assignments per loop\n",
    "output = []\n",
    "for file in file_names[:]:\n",
    "    notebook = read_notebook(file)\n",
    "    extracted_cells = extract_cells(notebook)\n",
    "    example = format_for_gpt(extracted_cells)\n",
    "    response_with_context = chain.invoke({\"input\": example})\n",
    "    output.append(response_with_context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('gpt_4_inference.jsonl', 'w') as file:\n",
    "    for i,evaluation in enumerate(output):\n",
    "        json_line = json.dumps(evaluation.content)  # Converting dictionary to JSON string\n",
    "        file.write(json_line + '\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,evaluation in enumerate(output):\n",
    "    feedback = evaluation.content.split(\"\\n\")\n",
    "    print(\"printing feedback for {}\".format(file_names[i]))\n",
    "    for points in feedback:\n",
    "        print(points)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
