{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.7/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -q torch openai "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.7/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -q langchain nbformat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    FewShotChatMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "import nbformat\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_notebook(notebook_path):\n",
    "        with open(notebook_path, 'r', encoding='utf-8') as f:\n",
    "            return nbformat.read(f, as_version=4)\n",
    "\n",
    "def extract_cells(notebook):\n",
    "    cells = []\n",
    "    for cell in notebook.cells:\n",
    "        if cell.cell_type in ['markdown', 'code']:\n",
    "            cells.append({\n",
    "                'type': cell.cell_type,\n",
    "                'content': cell.source\n",
    "            })\n",
    "    return cells\n",
    "\n",
    "def format_for_gpt(cells):\n",
    "    formatted_data = {\n",
    "        \"cells\": cells\n",
    "    }\n",
    "    return json.dumps(formatted_data, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook = read_notebook(\"/Users/shobanasiranjeevilu/Downloads/sample_work/sample_work/sample_assignments/assignment_4.ipynb\")\n",
    "extracted_cells = extract_cells(notebook)\n",
    "formatted_data = format_for_gpt(extracted_cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n    \"cells\": [\\n        {\\n            \"type\": \"code\",\\n            \"content\": \"import pandas as pd\"\\n        },\\n        {\\n            \"type\": \"code\",\\n            \"content\": \"df=pd.read_csv(\\\\\"yelp_2.csv\\\\\")\\\\ndf\"\\n        },\\n        {\\n            \"type\": \"markdown\",\\n            \"content\": \"Average number of words in each review (define \\\\u201cwords\\\\u201d however you like but be explicit about it)\"\\n        },\\n        {\\n            \"type\": \"code\",\\n            \"content\": \"import pandas as pd\\\\n\\\\n\\\\ndata = {\\\\n    \\'Unnamed: 0\\': [0, 1, 2, 3, 4],\\\\n    \\'text\\': [\\\\n        \\\\\"My wife took me here on my birthday for breakfast\\\\\",\\\\n        \\\\\"I have no idea why some people give bad reviews\\\\\",\\\\n        \\\\\"Love the gyro plate. Rice is so good and I also...\\\\\",\\\\n        \\\\\"Rosie, Dakota, and I LOVE Chaparral Dog Park!!...\\\\\",\\\\n        \\\\\"General Manager Scott Petello is a good egg!!!...\\\\\"\\\\n    ]\\\\n}\\\\n\\\\n\\\\ndf = pd.DataFrame(data)\\\\n\\\\n\\\\ndef count_words(text):\\\\n    words = text.split()\\\\n    return len(words)\\\\n\\\\n\\\\ndf[\\'word_count\\'] = df[\\'text\\'].apply(count_words)\\\\n\\\\n\\\\naverage_words_per_review = df[\\'word_count\\'].mean()\\\\n\\\\nprint(\\\\\"Average number of words in each review:\\\\\", average_words_per_review)\\\\n\"\\n        },\\n        {\\n            \"type\": \"markdown\",\\n            \"content\": \"Count of reviews by year-month (eg \\\\u201c2021-09\\\\u201d)\"\\n        },\\n        {\\n            \"type\": \"code\",\\n            \"content\": \"import pandas as pd\\\\n\\\\n\\\\ndata = {\\\\n    \\'date\\': [\\\\n        \\'2011-01-26\\', \\'2011-07-27\\', \\'2012-06-14\\', \\'2010-05-27\\', \\'2012-01-05\\'\\\\n    ],\\\\n    \\'text\\': [\\\\n        \\\\\"My wife took me here on my birthday for breakfast\\\\\",\\\\n        \\\\\"I have no idea why some people give bad reviews\\\\\",\\\\n        \\\\\"Love the gyro plate. Rice is so good and I also...\\\\\",\\\\n        \\\\\"Rosie, Dakota, and I LOVE Chaparral Dog Park!!...\\\\\",\\\\n        \\\\\"General Manager Scott Petello is a good egg!!!...\\\\\"\\\\n    ]\\\\n}\\\\n\\\\n\\\\ndf = pd.DataFrame(data)\\\\n\\\\n\\\\ndf[\\'date\\'] = pd.to_datetime(df[\\'date\\'])\\\\n\\\\n\\\\ndf[\\'year_month\\'] = df[\\'date\\'].dt.strftime(\\'%Y-%m\\')\\\\n\\\\n\\\\nreviews_by_year_month = df.groupby(\\'year_month\\').size().reset_index(name=\\'review_count\\')\\\\n\\\\nprint(reviews_by_year_month)\\\\n\"\\n        },\\n        {\\n            \"type\": \"markdown\",\\n            \"content\": \"Average rating of any review marked \\\\u201dcool\\\\u201d (eg where cool != 0)\"\\n        },\\n        {\\n            \"type\": \"code\",\\n            \"content\": \"import pandas as pd\\\\n\\\\n\\\\ndata = {\\\\n    \\'cool\\': [2, 0, 0, 1, 0],\\\\n    \\'stars\\': [5, 5, 4, 5, 5]\\\\n}\\\\n\\\\n\\\\ndf = pd.DataFrame(data)\\\\n\\\\n\\\\ncool_reviews = df[df[\\'cool\\'] != 0]\\\\n\\\\n\\\\naverage_rating_cool_reviews = cool_reviews[\\'stars\\'].mean()\\\\n\\\\nprint(\\\\\"Average rating of \\'cool\\' reviews:\\\\\", average_rating_cool_reviews)\\\\n\"\\n        },\\n        {\\n            \"type\": \"code\",\\n            \"content\": \"\"\\n        }\\n    ]\\n}'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(temperature=0, model_name=\"gpt-4\", openai_api_key=\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(\n",
    "        content=\"\"\" You are a helpful assistant that evaluate python program and grad from 1-100 \n",
    "        and explain why you gave such grade. make sure to provide your response in bullet points\"\"\"\n",
    "    ),\n",
    "    HumanMessage(\n",
    "        content=  formatted_data )\n",
    "]\n",
    "response = chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Grade: 90 out of 100\n",
      "Feedback: The code is well-structured and organized into different cells, each performing a specific task. This makes the code easy to read and understand.\n",
      "Grade points: 20 points\n",
      "Feedback: The code uses pandas, a powerful data analysis library in Python, to perform operations on the data. This is a good choice for handling data in Python.\n",
      "Grade points: 20 points\n",
      "Feedback: The code correctly calculates the average number of words in each review, the count of reviews by year-month, and the average rating of any review marked as \"cool\". The logic used in these calculations is correct.\n",
      "Grade points: 30 points\n",
      "Feedback: The code uses the `apply` function to apply a function to each element in a column of the DataFrame. This is a good use of pandas functionality.\n",
      "Grade points: 10 points\n",
      "Feedback: The code uses the `groupby` function to group the data by year-month and count the number of reviews in each group. This is a good use of pandas functionality.\n",
      "Grade points: 10 points\n",
      "Feedback: The code does not handle potential errors. For example, if the data file does not exist or cannot be read, the code will crash. It would be better to include error handling to make the code more robust.\n",
      "Grade points: -5 points\n",
      "Feedback: The code does not include any comments to explain what it is doing. While the code is relatively straightforward, comments would still be helpful for understanding the code.\n",
      "Grade points: -5 points\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "overall_grade = re.search(r\"(\\d+) out of 100\", response.content)\n",
    "points = re.findall(r\"- (.+?)\\s+\\(\\+?(-?\\d+) points\\)\", response.content)\n",
    "print(f\"Overall Grade: {overall_grade.group(1)} out of 100\")\n",
    "for point, grade_change in points:\n",
    "    print(f\"Feedback: {point}\\nGrade points: {grade_change} points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instruction prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(\n",
    "        content=\"\"\" You are a grading bot that will help a teaching assistant grade student submissions for a programming task. Please follow the\n",
    "                instructions below to grade the student submission. In your assessment, you must always fill in the following bullet points:\n",
    "                Grade: 0-100\n",
    "                Summarised feedback: A short one or two sentence summary of your assessment.\n",
    "                Possible errors: Write any errors that you might find in a bullet point list. If you find noerrors, write \"None\". If there are several,\n",
    "                which there very well might be, please list them all.\n",
    "                \n",
    "                You shall under no circumstanses comment on unnecessary improvements, only those who are relevant to the task. Only comment on mistakes\n",
    "                that makes the code fail the requirements of the task. Elements such as effiency is not relevant if its not explicitly a requirement\n",
    "                of the task.\"\"\"\n",
    "    ),\n",
    "    HumanMessage(\n",
    "        content=  formatted_data )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grade: 100\n",
      "Summarised Feedback: The student has successfully completed all the tasks as per the requirements. The code is correct and produces the expected output.\n",
      "Possible Errors: None\n"
     ]
    }
   ],
   "source": [
    "grade = re.search(r\"Grade: (\\d+)\", response.content)\n",
    "summarised_feedback = re.search(r\"Summarised feedback: (.+)\", response.content)\n",
    "possible_errors = re.search(r\"Possible errors: (.+)\", response.content)\n",
    "\n",
    "# Displaying the results\n",
    "grade = grade.group(1) if grade else \"Unknown\"\n",
    "summarised_feedback = summarised_feedback.group(1) if summarised_feedback else \"No feedback provided\"\n",
    "possible_errors = possible_errors.group(1) if possible_errors else \"No errors listed\"\n",
    "\n",
    "print(f\"Grade: {grade}\")\n",
    "print(f\"Summarised Feedback: {summarised_feedback}\")\n",
    "print(f\"Possible Errors: {possible_errors}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few shot prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 1\n",
    "notebook = read_notebook(\"/Users/shobanasiranjeevilu/Downloads/sample_work/sample_work/sample_assignments/assignment_3.ipynb\")\n",
    "extracted_cells = extract_cells(notebook)\n",
    "example_1 = format_for_gpt(extracted_cells)\n",
    "\n",
    "#Example 2\n",
    "\n",
    "notebook = read_notebook(\"/Users/shobanasiranjeevilu/Downloads/sample_work/sample_work/sample_assignments/assignment_2.ipynb\")\n",
    "extracted_cells = extract_cells(notebook)\n",
    "example_2 = format_for_gpt(extracted_cells)\n",
    "\n",
    "#Example 3\n",
    "\n",
    "notebook = read_notebook(\"/Users/shobanasiranjeevilu/Downloads/sample_work/sample_work/sample_assignments/assignment_7.ipynb\")\n",
    "extracted_cells = extract_cells(notebook)\n",
    "example_3 = format_for_gpt(extracted_cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\"input\": example_1, \"output\": \"Grade:85, summarized Feedback: Question2 is not executable, Question3 gives no output. Add notebook with executed output/ output files next time, Possible Errors: None\" },\n",
    "    {\"input\": example_2, \"output\": \"Grade:85, summarized Feedback: Question 1 will not execute, Possible Errors: Incorrect class name is used while invoking\"},\n",
    "    {'input': example_3, \"output\": \"Grade:20, summarized Feedback: No map/reduce logic has been written to do the task. DataFrames are not allowed\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"user\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    \n",
    "    input_variables=[\"input\"],\n",
    "    examples=examples,\n",
    "    example_prompt= example_prompt\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: {\n",
      "    \"cells\": [\n",
      "        {\n",
      "            \"type\": \"code\",\n",
      "            \"content\": \"!pip install MRJob\\n!pip install python-dateutil\"\n",
      "        },\n",
      "        {\n",
      "            \"type\": \"code\",\n",
      "            \"content\": \"from google.colab import drive\\ndrive.mount('/content/drive')\\nimport pandas as pd\\ndata = pd.read_csv('/content/drive/MyDrive/bigdata/yelp.csv')\"\n",
      "        },\n",
      "        {\n",
      "            \"type\": \"code\",\n",
      "            \"content\": \"%%file average_words_per_review.py\\nfrom mrjob.job import MRJob\\nclass MRAverageWordsPerReview(MRJob):\\n    def mapper(self, _, line):\\n        # Assuming each line is a review.\\n        words = line.split()\\n        yield \\\"review\\\", len(words)\\n    def reducer(self, key, values):\\n        total_words = 0\\n        total_reviews = 0\\n        for value in values:\\n            total_words += value\\n            total_reviews += 1\\n        average_words = total_words / total_reviews\\n        yield key, average_words\\nif __name__ == '__main__':\\n    MRAverageWordsPerReview.run()\"\n",
      "        },\n",
      "        {\n",
      "            \"type\": \"code\",\n",
      "            \"content\": \"!python average_words_per_review.py yelp.csv\"\n",
      "        },\n",
      "        {\n",
      "            \"type\": \"code\",\n",
      "            \"content\": \"%%file reviewby_year_month.py\\nfrom mrjob.job import MRJob\\nimport dateutil.parser\\nclass MRReviewsByYearMonth(MRJob):\\n    def mapper(self, _, line):\\n        data = line.strip().split('\\\\t')\\n        date_str = data[4]\\n        try:\\n            date = dateutil.parser.parse(date_str)\\n            year_month = date.strftime('%Y-%m')\\n            yield year_month, 1\\n        except:\\n            pass\\n    def reducer(self, year_month, counts):\\n        yield year_month, sum(counts)\\nif __name__ == '__main__':\\n    MRReviewsByYearMonth.run()\\n\"\n",
      "        },\n",
      "        {\n",
      "            \"type\": \"code\",\n",
      "            \"content\": \"!python reviewby_year_month.py yelp.csv\"\n",
      "        },\n",
      "        {\n",
      "            \"type\": \"code\",\n",
      "            \"content\": \"%%file avg_rating_coolreview.py\\nfrom mrjob.job import MRJob\\nclass MRAvgRatingCoolReviews(MRJob):\\n    def mapper(self, _, line):\\n        data = line.strip().split('\\\\t')\\n        try:\\n            cool_value = int(data[7])\\n            stars = float(data[3])\\n            if cool_value != 0:\\n                yield None, (stars, 1)\\n        except:\\n            pass\\n    def reducer(self, _, star_counts):\\n        totalstars = 0\\n        total_coolreviews = 0\\n        for stars, count in star_counts:\\n            totalstars += stars\\n            total_coolreviews += count\\n        if total_coolreviews != 0:\\n            average_rating = totalstars / total_coolreviews\\n            yield \\\"Average Rating for Cool Reviews\\\", average_rating\\nif __name__ == '__main__':\\n    MRAvgRatingCoolReviews.run()\\n\"\n",
      "        },\n",
      "        {\n",
      "            \"type\": \"code\",\n",
      "            \"content\": \"!python avg_rating_coolreview.py yelp.csv\"\n",
      "        },\n",
      "        {\n",
      "            \"type\": \"code\",\n",
      "            \"content\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "AI: Grade:85, summarized Feedback: Question2 is not executable, Question3 gives no output. Add notebook with executed output/ output files next time, Possible Errors: None\n",
      "Human: {\n",
      "    \"cells\": [\n",
      "        {\n",
      "            \"type\": \"code\",\n",
      "            \"content\": \"import pandas as pd\\ndf=pd.read_csv(r\\\"C:\\\\Users\\\\Sai Kiran\\\\Downloads\\\\dataset\\\\yelp.csv\\\")\\ndf = df.replace(r'\\\\n',' ', regex=True)\\ndf.to_csv(\\\"yelp_modified.csv\\\")\\ndf.head()\"\n",
      "        },\n",
      "        {\n",
      "            \"type\": \"code\",\n",
      "            \"content\": \"1#.Average number of words in each review (define \\u201cwords\\u201d however you like but be explicit about it)\"\n",
      "        },\n",
      "        {\n",
      "            \"type\": \"code\",\n",
      "            \"content\": \"%%file wordcount.py\\nfrom mrjob.job import MRJob\\nimport csv\\n\\nclass Average_no_of_words_in_review(MRJob):\\n\\n    def mapper(self, _, line):\\n        fields = next(csv.reader([line]))\\n        if len(fields) >= 11:\\n            text = fields[10]  # Assuming the text column is at index 10\\n            words = text.split()\\n            yield \\\"word_count\\\", len(words)\\n            yield \\\"review_count\\\", 1\\n\\n    def reducer(self, key, values):\\n        if key == \\\"word_count\\\":\\n            total_words = sum(values)\\n        elif key == \\\"review_count\\\":\\n            total_reviews = sum(values)\\n\\n        if total_reviews > 0:\\n            avg_no_of_words_per_review = total_words / total_reviews\\n            yield \\\"Average Number of Words Per Review\\\", avg_no_of_words_per_review\\n\\nif __name__ == '__main__':\\n    Average_no_of_words_in_review.run()\\n\"\n",
      "        },\n",
      "        {\n",
      "            \"type\": \"code\",\n",
      "            \"content\": \"import wordcount\\nmr_job = wordcount.AvgWordCount(args=['yelp_2.csv'])\\nwith mr_job.make_runner() as runner:\\n    runner.run()\\n    for key, value in mr_job.parse_output(runner.cat_output()):\\n        print(key,value)\"\n",
      "        },\n",
      "        {\n",
      "            \"type\": \"code\",\n",
      "            \"content\": \"#2.Count of reviews by year-month (eg \\u201c2021-09\\u201d)\\n\"\n",
      "        },\n",
      "        {\n",
      "            \"type\": \"code\",\n",
      "            \"content\": \"%%file count_of_review_yearmonth.py\\nfrom mrjob.job import MRJob\\nimport csv\\n\\nclass count_of_review_yearmonth(MRJob):\\n\\n     CSV_FILE = r'C:\\\\Users\\\\Sai Kiran\\\\Downloads\\\\dataset\\\\yelp.csv'\\n    def mapper(self, _, line):\\n        fields = next(csv.reader([line]))\\n        if len(fields) >= 3:  #the date column is at index 3\\n            date = fields[2]\\n            year_month = date[:7]  # Extract the year and month (e.g., \\\"2021-09\\\")\\n            yield year_month, 1\\n\\n    def reducer(self, year_month, counts):\\n        total_reviews = sum(counts)\\n        yield year_month, total_reviews\\n\\nif __name__ == '__main__':\\n    count_of_review_yearmonth.run()\\n\"\n",
      "        },\n",
      "        {\n",
      "            \"type\": \"code\",\n",
      "            \"content\": \"import count_of_review_yearmonth\\nmr_job = count_of_review_yearmonth.count_of_review_yearmonth(args=['yelp_2.csv'])\\nwith mr_job.make_runner() as runner:\\n    runner.run()\\n    for key, value in mr_job.parse_output(runner.cat_output()):\\n        print(key,value)\"\n",
      "        },\n",
      "        {\n",
      "            \"type\": \"code\",\n",
      "            \"content\": \"#3.Average rating of any review marked \\u201dcool\\u201d (eg where cool != 0)\\n\"\n",
      "        },\n",
      "        {\n",
      "            \"type\": \"code\",\n",
      "            \"content\": \"%%file Average_rating_forcool.py\\nfrom mrjob.job import MRJob\\nimport csv\\n\\nclass Average_rating_forcool(MRJob):\\n\\n    def mapper(self, _, line):\\n        fields = next(csv.reader([line]))\\n        if len(fields) >= 10:\\n            cool, stars = fields[8], fields[4]\\n            \\n            # Check if 'cool' is not zero and 'stars' is not the header\\n            if cool != '0' and stars != 'stars':\\n                yield None, float(stars)\\n\\n    def reducer(self, _, stars):\\n        list_stars = list(stars)\\n        if list_stars:\\n            average_star_rating = sum(list_stars) / len(list_stars)\\n            yield \\\"Average rating of any review marked cool \\\", average_star_rating\\n\\nif __name__ == '__main__':\\n    Average_rating_forcool.run()\\n\"\n",
      "        },\n",
      "        {\n",
      "            \"type\": \"code\",\n",
      "            \"content\": \"import Average_rating_forcool\\nmr_job = Average_rating_forcool.Average_rating_forcool(args=['yelp_2.csv'])\\nwith mr_job.make_runner() as runner:\\n    runner.run()\\n    for key, value in mr_job.parse_output(runner.cat_output()):\\n        print(\\\"Average rating of any review marked cool is \\\",value)\"\n",
      "        },\n",
      "        {\n",
      "            \"type\": \"code\",\n",
      "            \"content\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "AI: Grade:85, summarized Feedback: Question 1 will not execute, Possible Errors: Incorrect class name is used while invoking\n"
     ]
    }
   ],
   "source": [
    "print(few_shot_prompt.format())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Few shot without context(Rubic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grade: 70\n",
      "\n",
      "Feedback:\n",
      "\n",
      "- The code is well-structured and easy to read.\n",
      "- The use of pandas for data manipulation is appropriate and efficient.\n",
      "- The logic used to solve the problems is correct and the code produces the expected results.\n",
      "- However, the code is not scalable. It works well for small datasets but for larger datasets, it would be more efficient to use a map-reduce framework like Hadoop or Spark.\n",
      "- The code could be improved by adding more comments to explain the logic and the steps.\n",
      "- The code could also be improved by defining functions for repeated code blocks.\n",
      "- The code does not handle exceptions or errors. It would be better to add error handling to make the code more robust.\n",
      "- The code does not have any unit tests. It would be better to add tests to ensure the code works as expected.\n"
     ]
    }
   ],
   "source": [
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant that evaluate python program and grad from 1-100 and \\\n",
    "         explain why you gave such grade. make sure to provide your response in bullet points\"),\n",
    "        few_shot_prompt,\n",
    "        (\"user\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "chain = final_prompt | chat\n",
    "response_without_context = chain.invoke({\"input\": formatted_data})\n",
    "points = response_without_context.content.split(\"\\n\")\n",
    "for point in points:\n",
    "    print(f\"{point}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### few shot with context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grade: 20, summarized Feedback: No map/reduce logic has been written to do the task. DataFrames are not allowed\n"
     ]
    }
   ],
   "source": [
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant that evaluate python program and grad from 1-100 and explain why you gave such grade. make sure to provide your response in bullet points\\\n",
    "         Write three Python scripts using mrjob that tell me:\\\n",
    "Average number of words in each review (define “words” however you like but be explicit about it)\\\n",
    "Count of reviews by year-month (eg “2021-09”)\\\n",
    "Average rating of any review marked ”cool” (eg where cool != 0)\"\n",
    "),\n",
    "        few_shot_prompt,\n",
    "        (\"user\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "chain = final_prompt | chat\n",
    "response_without_context = chain.invoke({\"input\": formatted_data})\n",
    "points = response_without_context.content.split(\"\\n\")\n",
    "for point in points:\n",
    "    print(f\"{point}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        So, I have inferenced a gpt-4 model to identify best prompting way to get the desired results on Evaluating student assignments. \n",
    "\n",
    "        Hence performing few-shot prompting has showed significant improvement but still the model focused more coding standards.\n",
    "\n",
    "        To improve further, provided content on what the model shoud be looking for in grading the assignments. With that I was able to achieve the desired output. \n",
    "\n",
    "        Using this techinique going forward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference on GPT  (few-shot prompting with context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant that evaluate programming assignments and check all the instructions are followed and grade it from 1-100 and provide Feedback what went wrong.Provide Reasoning on why you gave such grade. \\\n",
    "            Given the dataset about weather in Australia , predict rain using models. \\\n",
    "         - must have used ML model to perform prediction. \\\n",
    "          - Include VectorAssembler successfully to perform feature transformation  \"\n",
    "),\n",
    "        \n",
    "        few_shot_prompt,\n",
    "        (\"user\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "chain = final_prompt | chat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '/Users/shobanasiranjeevilu/Downloads/sample_work/sample_work/inference'\n",
    "file_names,files = [],[]\n",
    "# Collecting .ipynb files and avoiding hidden/system files\n",
    "for file in os.listdir(folder_path):\n",
    "    full_path = os.path.join(folder_path, file)\n",
    "    if os.path.isfile(full_path) and file.endswith('.ipynb') and not file.startswith('.'):\n",
    "        file_names.append(full_path)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To avoid RateLimitException taking 3 assignments per loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = []\n",
    "for file in file_names[:3]:\n",
    "    notebook = read_notebook(file)\n",
    "    extracted_cells = extract_cells(notebook)\n",
    "    example = format_for_gpt(extracted_cells)\n",
    "    response_with_context = chain.invoke({\"input\": example})\n",
    "    output.append(response_with_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in file_names[3:6]:\n",
    "    notebook = read_notebook(file)\n",
    "    extracted_cells = extract_cells(notebook)\n",
    "    example = format_for_gpt(extracted_cells)\n",
    "    response_with_context = chain.invoke({\"input\": example})\n",
    "    output.append(response_with_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in file_names[6:9]:\n",
    "    notebook = read_notebook(file)\n",
    "    extracted_cells = extract_cells(notebook)\n",
    "    example = format_for_gpt(extracted_cells)\n",
    "    response_with_context = chain.invoke({\"input\": example})\n",
    "    output.append(response_with_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in file_names[9:]:\n",
    "    notebook = read_notebook(file)\n",
    "    extracted_cells = extract_cells(notebook)\n",
    "    example = format_for_gpt(extracted_cells)\n",
    "    response_with_context = chain.invoke({\"input\": example})\n",
    "    output.append(response_with_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/shobanasiranjeevilu/Downloads/sample_work/sample_work/inference/assignment_4.ipynb',\n",
       " '/Users/shobanasiranjeevilu/Downloads/sample_work/sample_work/inference/assignment_6.ipynb',\n",
       " '/Users/shobanasiranjeevilu/Downloads/sample_work/sample_work/inference/assignment_10.ipynb',\n",
       " '/Users/shobanasiranjeevilu/Downloads/sample_work/sample_work/inference/assignment_1.ipynb',\n",
       " '/Users/shobanasiranjeevilu/Downloads/sample_work/sample_work/inference/assignment_3.ipynb',\n",
       " '/Users/shobanasiranjeevilu/Downloads/sample_work/sample_work/inference/assignment_7.ipynb',\n",
       " '/Users/shobanasiranjeevilu/Downloads/sample_work/sample_work/inference/assignmebt_2.ipynb',\n",
       " '/Users/shobanasiranjeevilu/Downloads/sample_work/sample_work/inference/assignment_5.ipynb',\n",
       " '/Users/shobanasiranjeevilu/Downloads/sample_work/sample_work/inference/assignment_9.ipynb',\n",
       " '/Users/shobanasiranjeevilu/Downloads/sample_work/sample_work/inference/assignment_8.ipynb']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content=\"Grade: 95\\n\\nThe student has done a good job in following the instructions. They have used a machine learning model (Random Forest) to predict whether it will rain or not. They have also used VectorAssembler for feature transformation. The code is well-structured and the logic is correct. \\n\\nHowever, the student has not provided any comments or explanations about the steps they are performing, which makes it a bit difficult to follow the logic. It would be better if they could provide some explanations or comments in their code. \\n\\nThe student could also improve their work by performing some exploratory data analysis before building the model. This would give them a better understanding of the data and could potentially improve the model's performance. \\n\\nFinally, the student could try using different machine learning models and compare their performance. This would give them a better understanding of which model works best for this particular problem.\"),\n",
       " AIMessage(content='Grade: 95\\n\\nThe assignment is almost perfect. The student has successfully used multiple machine learning models to predict rain, including RandomForestClassifier, DecisionTreeClassifier, GBTClassifier, and LogisticRegression. The VectorAssembler was also used effectively to perform feature transformation. \\n\\nThe student has also evaluated the models using the AUC-ROC metric and RMSE, which is a good practice. \\n\\nHowever, the student could improve the assignment by handling missing values more effectively. Currently, the student is filling missing values with 0, which might not be the best strategy for all columns. It would be better to use a more sophisticated method for handling missing values, such as imputation. \\n\\nAdditionally, the student could improve the assignment by performing some exploratory data analysis before building the models. This would provide valuable insights about the data and could potentially improve the performance of the models. \\n\\nFinally, the student could improve the assignment by tuning the hyperparameters of the models. This could potentially improve the performance of the models. \\n\\nOverall, the student has done a great job on this assignment. The code is well-organized and easy to follow, and the student has demonstrated a good understanding of machine learning and PySpark.'),\n",
       " AIMessage(content='Grade: 70, summarized Feedback: The student has not used any ML model to perform prediction.'),\n",
       " AIMessage(content='Grade: 95\\n\\nThe assignment is almost perfect. The student has successfully used a machine learning model (Random Forest Classifier) to predict whether it will rain tomorrow in Australia. The student has also successfully used VectorAssembler to perform feature transformation. The student has also done a good job in handling missing values and balancing the dataset.\\n\\nHowever, the student has not provided any explanation or comments in the code to explain what each part of the code does. This makes it difficult for others to understand the code. Also, the student has not provided any analysis or interpretation of the results. For example, the student could have discussed the accuracy of the model and whether it is satisfactory.\\n\\nReasoning:\\n\\n- The student has successfully used a machine learning model to perform prediction, as required by the assignment.\\n- The student has successfully used VectorAssembler to perform feature transformation, as required by the assignment.\\n- The student has handled missing values and balanced the dataset, which are good practices in machine learning.\\n- The student has not provided any explanation or comments in the code, which makes it difficult for others to understand the code.\\n- The student has not provided any analysis or interpretation of the results, which is an important part of any data analysis project.'),\n",
       " AIMessage(content='Grade: 95\\n\\nThe assignment is almost perfect. The student has successfully used a machine learning model (Logistic Regression) to predict rain in Australia. The student has also successfully used VectorAssembler to perform feature transformation. The student has also done a good job in handling missing values in the dataset. \\n\\nHowever, there are a few minor issues that need to be addressed:\\n\\n1. The student has dropped the \"selected_numerical_features\" column from the dataframe, which is not necessary and could potentially lead to errors since this column does not exist in the dataframe. \\n\\n2. The student has not provided any explanation or comments in the code, which makes it difficult to understand the logic and flow of the code. \\n\\n3. The student has not visualized the data or the results, which is an important part of any data analysis task. \\n\\n4. The student has not split the data into training and testing sets, which is a crucial step in any machine learning task. \\n\\nOverall, the student has done a good job, but there is room for improvement.'),\n",
       " AIMessage(content=\"Grade: 95\\n\\nThe code provided is well-structured and follows the instructions given in the assignment. The student has used a Machine Learning model (Decision Tree Classifier) to predict whether it will rain tomorrow in Australia based on weather data. The student has also successfully used VectorAssembler to perform feature transformation, which is a requirement in the assignment.\\n\\nHowever, the student has not provided any output for the code, so it's not possible to verify if the code runs successfully and produces the expected results. Therefore, I have deducted 5 points. \\n\\nIn the future, please provide the output of your code or a link to a notebook where the code has been run. This will allow for a more accurate evaluation of your work.\"),\n",
       " AIMessage(content=\"Grade: 95\\n\\nThe assignment is almost perfect. The student successfully loaded the dataset, preprocessed the data (handled missing values, converted categorical variables to numerical), split the data into training and testing sets, trained a Random Forest model, made predictions, and evaluated the model using accuracy. \\n\\nHowever, the assignment lacks the use of VectorAssembler for feature transformation as per the instructions. VectorAssembler is a feature transformer that merges multiple columns into a vector column. It's commonly used in PySpark's MLlib library, not in scikit-learn. The student might have misunderstood the instructions or the context. \\n\\nFeedback: \\n1. The assignment is well done, but it lacks the use of VectorAssembler for feature transformation. Please make sure to follow all the instructions.\\n2. It's good to see that you've handled missing values and categorical variables before training the model. This is a crucial step in any machine learning project.\\n3. Your model evaluation using accuracy is correct. However, consider using other metrics like precision, recall, or F1 score for a more comprehensive evaluation, especially for imbalanced datasets.\\n4. Keep up the good work!\"),\n",
       " AIMessage(content='Grade: 95\\n\\nThe code provided does a good job of following the instructions. It uses a machine learning model (Random Forest Classifier) to predict whether it will rain tomorrow in Australia based on weather data. It also successfully uses the VectorAssembler to perform feature transformation. \\n\\nHowever, there are a few areas where the code could be improved:\\n\\n1. The handling of missing values could be more sophisticated. Simply replacing all missing values with 0 may not be the best approach, especially for numerical columns. It would be better to use a method that takes into account the distribution of the data, such as mean or median imputation.\\n\\n2. The code does not include any exploratory data analysis or visualization. While this was not explicitly required in the instructions, it is generally a good practice to include this in a data science project.\\n\\n3. The code does not include any comments explaining what each section of the code does. This makes it harder for others to understand the code.\\n\\n4. The code does not include any evaluation of the model beyond a simple accuracy score. It would be helpful to include other metrics, such as precision, recall, and F1 score, as well as a confusion matrix. \\n\\n5. The code does not include any hyperparameter tuning or cross-validation. This could potentially improve the performance of the model. \\n\\nOverall, the code does a good job of following the instructions and should be able to make accurate predictions. However, there are several areas where the code could be improved.'),\n",
       " AIMessage(content='Grade: 95\\n\\nThe assignment is almost perfect. The student has successfully used a machine learning model (LinearSVC and RandomForestClassifier) to predict rain and has also included VectorAssembler to perform feature transformation. The code is well-structured and easy to follow. The student has also done a good job in data preprocessing and feature engineering.\\n\\nHowever, there are a few areas that could be improved:\\n\\n1. The student could have provided more explanation or comments in the code to make it easier to understand what each block of code is doing.\\n2. The student could have visualized the data or the results to make the analysis more comprehensive.\\n3. The student could have tried more models or techniques to improve the prediction accuracy.\\n\\nOverall, the student has done a good job in this assignment. The student has demonstrated a good understanding of machine learning and PySpark.'),\n",
       " AIMessage(content='Grade: 95\\n\\nThe assignment is almost perfect. The student has successfully used a machine learning model (Logistic Regression) to predict rain in Australia. The student has also successfully included VectorAssembler to perform feature transformation. The student has shown a good understanding of data preprocessing, feature engineering, and model evaluation. \\n\\nHowever, there are a few areas that could be improved:\\n\\n1. The student could have tried more than one machine learning model for the prediction task. This would have allowed for a comparison of the performance of different models on the same task.\\n\\n2. The student could have performed some exploratory data analysis (EDA) before building the model. This would have provided insights into the data and could have informed the feature engineering process.\\n\\n3. The student could have explained the steps and the code more clearly. While the code is well-structured and well-commented, a brief explanation of the steps and the reasoning behind them would have been helpful.\\n\\n4. The student could have visualized the results of the model evaluation. Visualizations can make the results more understandable and can provide insights that are not immediately obvious from the raw numbers.\\n\\nOverall, the assignment is very good and shows a strong understanding of machine learning and data processing with PySpark. The student just needs to work on the areas mentioned above to make it perfect.')]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gpt_4_inference.jsonl', 'w') as file:\n",
    "    for i,evaluation in enumerate(output):\n",
    "        json_line = json.dumps(evaluation.content)  # Converting dictionary to JSON string\n",
    "        file.write(json_line + '\\n') \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/shobanasiranjeevilu/Downloads/sample_work/sample_work/inference/assignment_4.ipynb\n",
      "Grade: 95\n",
      "\n",
      "The student has done a good job in following the instructions. They have used a machine learning model (Random Forest) to predict whether it will rain or not. They have also used VectorAssembler for feature transformation. The code is well-structured and the logic is correct. \n",
      "\n",
      "However, the student has not provided any comments or explanations about the steps they are performing, which makes it a bit difficult to follow the logic. It would be better if they could provide some explanations or comments in their code. \n",
      "\n",
      "The student could also improve their work by performing some exploratory data analysis before building the model. This would give them a better understanding of the data and could potentially improve the model's performance. \n",
      "\n",
      "Finally, the student could try using different machine learning models and compare their performance. This would give them a better understanding of which model works best for this particular problem.\n",
      "/Users/shobanasiranjeevilu/Downloads/sample_work/sample_work/inference/assignment_6.ipynb\n",
      "Grade: 95\n",
      "\n",
      "The assignment is almost perfect. The student has successfully used multiple machine learning models to predict rain, including RandomForestClassifier, DecisionTreeClassifier, GBTClassifier, and LogisticRegression. The VectorAssembler was also used effectively to perform feature transformation. \n",
      "\n",
      "The student has also evaluated the models using the AUC-ROC metric and RMSE, which is a good practice. \n",
      "\n",
      "However, the student could improve the assignment by handling missing values more effectively. Currently, the student is filling missing values with 0, which might not be the best strategy for all columns. It would be better to use a more sophisticated method for handling missing values, such as imputation. \n",
      "\n",
      "Additionally, the student could improve the assignment by performing some exploratory data analysis before building the models. This would provide valuable insights about the data and could potentially improve the performance of the models. \n",
      "\n",
      "Finally, the student could improve the assignment by tuning the hyperparameters of the models. This could potentially improve the performance of the models. \n",
      "\n",
      "Overall, the student has done a great job on this assignment. The code is well-organized and easy to follow, and the student has demonstrated a good understanding of machine learning and PySpark.\n",
      "/Users/shobanasiranjeevilu/Downloads/sample_work/sample_work/inference/assignment_10.ipynb\n",
      "Grade: 70, summarized Feedback: The student has not used any ML model to perform prediction.\n",
      "/Users/shobanasiranjeevilu/Downloads/sample_work/sample_work/inference/assignment_1.ipynb\n",
      "Grade: 95\n",
      "\n",
      "The assignment is almost perfect. The student has successfully used a machine learning model (Random Forest Classifier) to predict whether it will rain tomorrow in Australia. The student has also successfully used VectorAssembler to perform feature transformation. The student has also done a good job in handling missing values and balancing the dataset.\n",
      "\n",
      "However, the student has not provided any explanation or comments in the code to explain what each part of the code does. This makes it difficult for others to understand the code. Also, the student has not provided any analysis or interpretation of the results. For example, the student could have discussed the accuracy of the model and whether it is satisfactory.\n",
      "\n",
      "Reasoning:\n",
      "\n",
      "- The student has successfully used a machine learning model to perform prediction, as required by the assignment.\n",
      "- The student has successfully used VectorAssembler to perform feature transformation, as required by the assignment.\n",
      "- The student has handled missing values and balanced the dataset, which are good practices in machine learning.\n",
      "- The student has not provided any explanation or comments in the code, which makes it difficult for others to understand the code.\n",
      "- The student has not provided any analysis or interpretation of the results, which is an important part of any data analysis project.\n",
      "/Users/shobanasiranjeevilu/Downloads/sample_work/sample_work/inference/assignment_3.ipynb\n",
      "Grade: 95\n",
      "\n",
      "The assignment is almost perfect. The student has successfully used a machine learning model (Logistic Regression) to predict rain in Australia. The student has also successfully used VectorAssembler to perform feature transformation. The student has also done a good job in handling missing values in the dataset. \n",
      "\n",
      "However, there are a few minor issues that need to be addressed:\n",
      "\n",
      "1. The student has dropped the \"selected_numerical_features\" column from the dataframe, which is not necessary and could potentially lead to errors since this column does not exist in the dataframe. \n",
      "\n",
      "2. The student has not provided any explanation or comments in the code, which makes it difficult to understand the logic and flow of the code. \n",
      "\n",
      "3. The student has not visualized the data or the results, which is an important part of any data analysis task. \n",
      "\n",
      "4. The student has not split the data into training and testing sets, which is a crucial step in any machine learning task. \n",
      "\n",
      "Overall, the student has done a good job, but there is room for improvement.\n",
      "/Users/shobanasiranjeevilu/Downloads/sample_work/sample_work/inference/assignment_7.ipynb\n",
      "Grade: 95\n",
      "\n",
      "The code provided is well-structured and follows the instructions given in the assignment. The student has used a Machine Learning model (Decision Tree Classifier) to predict whether it will rain tomorrow in Australia based on weather data. The student has also successfully used VectorAssembler to perform feature transformation, which is a requirement in the assignment.\n",
      "\n",
      "However, the student has not provided any output for the code, so it's not possible to verify if the code runs successfully and produces the expected results. Therefore, I have deducted 5 points. \n",
      "\n",
      "In the future, please provide the output of your code or a link to a notebook where the code has been run. This will allow for a more accurate evaluation of your work.\n",
      "/Users/shobanasiranjeevilu/Downloads/sample_work/sample_work/inference/assignmebt_2.ipynb\n",
      "Grade: 95\n",
      "\n",
      "The assignment is almost perfect. The student successfully loaded the dataset, preprocessed the data (handled missing values, converted categorical variables to numerical), split the data into training and testing sets, trained a Random Forest model, made predictions, and evaluated the model using accuracy. \n",
      "\n",
      "However, the assignment lacks the use of VectorAssembler for feature transformation as per the instructions. VectorAssembler is a feature transformer that merges multiple columns into a vector column. It's commonly used in PySpark's MLlib library, not in scikit-learn. The student might have misunderstood the instructions or the context. \n",
      "\n",
      "Feedback: \n",
      "1. The assignment is well done, but it lacks the use of VectorAssembler for feature transformation. Please make sure to follow all the instructions.\n",
      "2. It's good to see that you've handled missing values and categorical variables before training the model. This is a crucial step in any machine learning project.\n",
      "3. Your model evaluation using accuracy is correct. However, consider using other metrics like precision, recall, or F1 score for a more comprehensive evaluation, especially for imbalanced datasets.\n",
      "4. Keep up the good work!\n",
      "/Users/shobanasiranjeevilu/Downloads/sample_work/sample_work/inference/assignment_5.ipynb\n",
      "Grade: 95\n",
      "\n",
      "The code provided does a good job of following the instructions. It uses a machine learning model (Random Forest Classifier) to predict whether it will rain tomorrow in Australia based on weather data. It also successfully uses the VectorAssembler to perform feature transformation. \n",
      "\n",
      "However, there are a few areas where the code could be improved:\n",
      "\n",
      "1. The handling of missing values could be more sophisticated. Simply replacing all missing values with 0 may not be the best approach, especially for numerical columns. It would be better to use a method that takes into account the distribution of the data, such as mean or median imputation.\n",
      "\n",
      "2. The code does not include any exploratory data analysis or visualization. While this was not explicitly required in the instructions, it is generally a good practice to include this in a data science project.\n",
      "\n",
      "3. The code does not include any comments explaining what each section of the code does. This makes it harder for others to understand the code.\n",
      "\n",
      "4. The code does not include any evaluation of the model beyond a simple accuracy score. It would be helpful to include other metrics, such as precision, recall, and F1 score, as well as a confusion matrix. \n",
      "\n",
      "5. The code does not include any hyperparameter tuning or cross-validation. This could potentially improve the performance of the model. \n",
      "\n",
      "Overall, the code does a good job of following the instructions and should be able to make accurate predictions. However, there are several areas where the code could be improved.\n",
      "/Users/shobanasiranjeevilu/Downloads/sample_work/sample_work/inference/assignment_9.ipynb\n",
      "Grade: 95\n",
      "\n",
      "The assignment is almost perfect. The student has successfully used a machine learning model (LinearSVC and RandomForestClassifier) to predict rain and has also included VectorAssembler to perform feature transformation. The code is well-structured and easy to follow. The student has also done a good job in data preprocessing and feature engineering.\n",
      "\n",
      "However, there are a few areas that could be improved:\n",
      "\n",
      "1. The student could have provided more explanation or comments in the code to make it easier to understand what each block of code is doing.\n",
      "2. The student could have visualized the data or the results to make the analysis more comprehensive.\n",
      "3. The student could have tried more models or techniques to improve the prediction accuracy.\n",
      "\n",
      "Overall, the student has done a good job in this assignment. The student has demonstrated a good understanding of machine learning and PySpark.\n",
      "/Users/shobanasiranjeevilu/Downloads/sample_work/sample_work/inference/assignment_8.ipynb\n",
      "Grade: 95\n",
      "\n",
      "The assignment is almost perfect. The student has successfully used a machine learning model (Logistic Regression) to predict rain in Australia. The student has also successfully included VectorAssembler to perform feature transformation. The student has shown a good understanding of data preprocessing, feature engineering, and model evaluation. \n",
      "\n",
      "However, there are a few areas that could be improved:\n",
      "\n",
      "1. The student could have tried more than one machine learning model for the prediction task. This would have allowed for a comparison of the performance of different models on the same task.\n",
      "\n",
      "2. The student could have performed some exploratory data analysis (EDA) before building the model. This would have provided insights into the data and could have informed the feature engineering process.\n",
      "\n",
      "3. The student could have explained the steps and the code more clearly. While the code is well-structured and well-commented, a brief explanation of the steps and the reasoning behind them would have been helpful.\n",
      "\n",
      "4. The student could have visualized the results of the model evaluation. Visualizations can make the results more understandable and can provide insights that are not immediately obvious from the raw numbers.\n",
      "\n",
      "Overall, the assignment is very good and shows a strong understanding of machine learning and data processing with PySpark. The student just needs to work on the areas mentioned above to make it perfect.\n"
     ]
    }
   ],
   "source": [
    "for i,evaluation in enumerate(output):\n",
    "    feedback = evaluation.content.split(\"\\n\")\n",
    "\n",
    "    print(file_names[i])\n",
    "\n",
    "    for points in feedback:\n",
    "        print(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
