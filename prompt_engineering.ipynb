{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing Prompt Engineering:\n",
    "        Identifying best Prompt to interact with Language model which results in meaningful output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please fill below variables with path to your example to execute \n",
    "        1. OpenAI_api_key\n",
    "        2. path_to_inference_notebook - sample notebook for zero shot prompting\n",
    "        3. path_to_example  - example path for few shot prompting\n",
    "        4. human_grade  - human provided grade for above example\n",
    "        5. human_feedback - human provided feedback for above example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.7/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -q torch openai "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.7/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -q langchain nbformat "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: Uses nbformat to parse Jupyter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    FewShotChatMessagePromptTemplate,\n",
    ")\n",
    "from utils import read_notebook,extract_cells,format_for_gpt, create_prompt_example\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_inference_notebook = \"\"\n",
    "notebook = read_notebook(path_to_inference_notebook)\n",
    "extracted_cells = extract_cells(notebook)\n",
    "formatted_data = format_for_gpt(extracted_cells)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keeping the same temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "OpenAI_api_key = \"\"\n",
    "chat = ChatOpenAI(temperature=0, model_name=\"gpt-4\", openai_api_key=OpenAI_api_key)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(\n",
    "        content=\"\"\" You are a helpful assistant that evaluate python program and grad from 1-100 \n",
    "        and explain why you gave such grade. make sure to provide your response in bullet points\"\"\"\n",
    "    ),\n",
    "    HumanMessage(\n",
    "        content=  formatted_data )\n",
    "]\n",
    "response = chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Grade: 90 out of 100\n",
      "Feedback: The code is well-structured and organized into different cells, each performing a specific task. This makes the code easy to read and understand.\n",
      "Grade points: 20 points\n",
      "Feedback: The code uses pandas, a powerful data analysis library in Python, to perform operations on the data. This is a good choice for handling data in Python.\n",
      "Grade points: 20 points\n",
      "Feedback: The code correctly calculates the average number of words in each review, the count of reviews by year-month, and the average rating of any review marked as \"cool\". The logic used in these calculations is correct.\n",
      "Grade points: 30 points\n",
      "Feedback: The code uses the `apply` function to apply a function to each element in a column of the DataFrame. This is a good use of pandas functionality.\n",
      "Grade points: 10 points\n",
      "Feedback: The code uses the `groupby` function to group the data by year-month and count the number of reviews in each group. This is a good use of pandas functionality.\n",
      "Grade points: 10 points\n",
      "Feedback: The code does not handle potential errors. For example, if the data file does not exist or cannot be read, the code will crash. It would be better to include error handling to make the code more robust.\n",
      "Grade points: -5 points\n",
      "Feedback: The code does not include any comments to explain what it is doing. While the code is relatively straightforward, comments would still be helpful for understanding the code.\n",
      "Grade points: -5 points\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "overall_grade = re.search(r\"(\\d+) out of 100\", response.content)\n",
    "points = re.findall(r\"- (.+?)\\s+\\(\\+?(-?\\d+) points\\)\", response.content)\n",
    "print(f\"Overall Grade: {overall_grade.group(1)} out of 100\")\n",
    "for point, grade_change in points:\n",
    "    print(f\"Feedback: {point}\\nGrade points: {grade_change} points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instruction prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(\n",
    "        content=\"\"\" You are a grading bot that will help a teaching assistant grade student submissions for a programming task. Please follow the\n",
    "                instructions below to grade the student submission. In your assessment, you must always fill in the following bullet points:\n",
    "                Grade: 0-100\n",
    "                Summarised feedback: A short one or two sentence summary of your assessment.\n",
    "                Possible errors: Write any errors that you might find in a bullet point list. If you find noerrors, write \"None\". If there are several,\n",
    "                which there very well might be, please list them all.\n",
    "                \n",
    "                You shall under no circumstanses comment on unnecessary improvements, only those who are relevant to the task. Only comment on mistakes\n",
    "                that makes the code fail the requirements of the task. Elements such as effiency is not relevant if its not explicitly a requirement\n",
    "                of the task.\"\"\"\n",
    "    ),\n",
    "    HumanMessage(\n",
    "        content=  formatted_data )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grade: 100\n",
      "Summarised Feedback: The student has successfully completed all the tasks as per the requirements. The code is correct and produces the expected output.\n",
      "Possible Errors: None\n"
     ]
    }
   ],
   "source": [
    "grade = re.search(r\"Grade: (\\d+)\", response.content)\n",
    "summarised_feedback = re.search(r\"Summarised feedback: (.+)\", response.content)\n",
    "possible_errors = re.search(r\"Possible errors: (.+)\", response.content)\n",
    "\n",
    "# Displaying the results\n",
    "grade = grade.group(1) if grade else \"Unknown\"\n",
    "summarised_feedback = summarised_feedback.group(1) if summarised_feedback else \"No feedback provided\"\n",
    "possible_errors = possible_errors.group(1) if possible_errors else \"No errors listed\"\n",
    "\n",
    "print(f\"Grade: {grade}\")\n",
    "print(f\"Summarised Feedback: {summarised_feedback}\")\n",
    "print(f\"Possible Errors: {possible_errors}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few shot prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: I consider 3 fewshot examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_1,human_feedback_example_1 = create_prompt_example(path_to_example=\"\",human_grade=\"\",human_feedback=\"\")\n",
    "example_2,human_feedback_example_2 = create_prompt_example(path_to_example=\"\",human_grade=\"\",human_feedback=\"\")\n",
    "example_3,human_feedback_example_3 = create_prompt_example(path_to_example=\"\",human_grade=\"\",human_feedback=\"\")\n",
    "\n",
    "\n",
    "examples = [\n",
    "    {\"input\": example_1, \"output\": human_feedback_example_1},\n",
    "    {\"input\": example_2, \"output\": human_feedback_example_2},\n",
    "    {'input': example_3, \"output\": human_feedback_example_3}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"user\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    \n",
    "    input_variables=[\"input\"],\n",
    "    examples=examples,\n",
    "    example_prompt= example_prompt\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: {\n",
      "    \"cells\": [\n",
      "        {\n",
      "            \"type\": \"code\",\n",
      "            \"content\": \"!pip install MRJob\\n!pip install python-dateutil\"\n",
      "        },\n",
      "        {\n",
      "            \"type\": \"code\",\n",
      "            \"content\": \"from google.colab import drive\\ndrive.mount('/content/drive')\\nimport pandas as pd\\ndata = pd.read_csv('/content/drive/MyDrive/bigdata/yelp.csv')\"\n",
      "        },\n",
      "        {\n",
      "            \"type\": \"code\",\n",
      "            \"content\": \"%%file average_words_per_review.py\\nfrom mrjob.job import MRJob\\nclass MRAverageWordsPerReview(MRJob):\\n    def mapper(self, _, line):\\n        # Assuming each line is a review.\\n        words = line.split()\\n        yield \\\"review\\\", len(words)\\n    def reducer(self, key, values):\\n        total_words = 0\\n        total_reviews = 0\\n        for value in values:\\n            total_words += value\\n            total_reviews += 1\\n        average_words = total_words / total_reviews\\n        yield key, average_words\\nif __name__ == '__main__':\\n    MRAverageWordsPerReview.run()\"\n",
      "        },\n",
      "        {\n",
      "            \"type\": \"code\",\n",
      "            \"content\": \"!python average_words_per_review.py yelp.csv\"\n",
      "        },\n",
      "        {\n",
      "            \"type\": \"code\",\n",
      "            \"content\": \"%%file reviewby_year_month.py\\nfrom mrjob.job import MRJob\\nimport dateutil.parser\\nclass MRReviewsByYearMonth(MRJob):\\n    def mapper(self, _, line):\\n        data = line.strip().split('\\\\t')\\n        date_str = data[4]\\n        try:\\n            date = dateutil.parser.parse(date_str)\\n            year_month = date.strftime('%Y-%m')\\n            yield year_month, 1\\n        except:\\n            pass\\n    def reducer(self, year_month, counts):\\n        yield year_month, sum(counts)\\nif __name__ == '__main__':\\n    MRReviewsByYearMonth.run()\\n\"\n",
      "        },\n",
      "        {\n",
      "            \"type\": \"code\",\n",
      "            \"content\": \"!python reviewby_year_month.py yelp.csv\"\n",
      "        },\n",
      "        {\n",
      "            \"type\": \"code\",\n",
      "            \"content\": \"%%file avg_rating_coolreview.py\\nfrom mrjob.job import MRJob\\nclass MRAvgRatingCoolReviews(MRJob):\\n    def mapper(self, _, line):\\n        data = line.strip().split('\\\\t')\\n        try:\\n            cool_value = int(data[7])\\n            stars = float(data[3])\\n            if cool_value != 0:\\n                yield None, (stars, 1)\\n        except:\\n            pass\\n    def reducer(self, _, star_counts):\\n        totalstars = 0\\n        total_coolreviews = 0\\n        for stars, count in star_counts:\\n            totalstars += stars\\n            total_coolreviews += count\\n        if total_coolreviews != 0:\\n            average_rating = totalstars / total_coolreviews\\n            yield \\\"Average Rating for Cool Reviews\\\", average_rating\\nif __name__ == '__main__':\\n    MRAvgRatingCoolReviews.run()\\n\"\n",
      "        },\n",
      "        {\n",
      "            \"type\": \"code\",\n",
      "            \"content\": \"!python avg_rating_coolreview.py yelp.csv\"\n",
      "        },\n",
      "        {\n",
      "            \"type\": \"code\",\n",
      "            \"content\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "AI: Grade:85, summarized Feedback: Question2 is not executable, Question3 gives no output. Add notebook with executed output/ output files next time, Possible Errors: None\n",
      "Human: {\n",
      "    \"cells\": [\n",
      "        {\n",
      "            \"type\": \"code\",\n",
      "            \"content\": \"import pandas as pd\\ndf=pd.read_csv(r\\\"C:\\\\Users\\\\Sai Kiran\\\\Downloads\\\\dataset\\\\yelp.csv\\\")\\ndf = df.replace(r'\\\\n',' ', regex=True)\\ndf.to_csv(\\\"yelp_modified.csv\\\")\\ndf.head()\"\n",
      "        },\n",
      "        {\n",
      "            \"type\": \"code\",\n",
      "            \"content\": \"1#.Average number of words in each review (define \\u201cwords\\u201d however you like but be explicit about it)\"\n",
      "        },\n",
      "        {\n",
      "            \"type\": \"code\",\n",
      "            \"content\": \"%%file wordcount.py\\nfrom mrjob.job import MRJob\\nimport csv\\n\\nclass Average_no_of_words_in_review(MRJob):\\n\\n    def mapper(self, _, line):\\n        fields = next(csv.reader([line]))\\n        if len(fields) >= 11:\\n            text = fields[10]  # Assuming the text column is at index 10\\n            words = text.split()\\n            yield \\\"word_count\\\", len(words)\\n            yield \\\"review_count\\\", 1\\n\\n    def reducer(self, key, values):\\n        if key == \\\"word_count\\\":\\n            total_words = sum(values)\\n        elif key == \\\"review_count\\\":\\n            total_reviews = sum(values)\\n\\n        if total_reviews > 0:\\n            avg_no_of_words_per_review = total_words / total_reviews\\n            yield \\\"Average Number of Words Per Review\\\", avg_no_of_words_per_review\\n\\nif __name__ == '__main__':\\n    Average_no_of_words_in_review.run()\\n\"\n",
      "        },\n",
      "        {\n",
      "            \"type\": \"code\",\n",
      "            \"content\": \"import wordcount\\nmr_job = wordcount.AvgWordCount(args=['yelp_2.csv'])\\nwith mr_job.make_runner() as runner:\\n    runner.run()\\n    for key, value in mr_job.parse_output(runner.cat_output()):\\n        print(key,value)\"\n",
      "        },\n",
      "        {\n",
      "            \"type\": \"code\",\n",
      "            \"content\": \"#2.Count of reviews by year-month (eg \\u201c2021-09\\u201d)\\n\"\n",
      "        },\n",
      "        {\n",
      "            \"type\": \"code\",\n",
      "            \"content\": \"%%file count_of_review_yearmonth.py\\nfrom mrjob.job import MRJob\\nimport csv\\n\\nclass count_of_review_yearmonth(MRJob):\\n\\n     CSV_FILE = r'C:\\\\Users\\\\Sai Kiran\\\\Downloads\\\\dataset\\\\yelp.csv'\\n    def mapper(self, _, line):\\n        fields = next(csv.reader([line]))\\n        if len(fields) >= 3:  #the date column is at index 3\\n            date = fields[2]\\n            year_month = date[:7]  # Extract the year and month (e.g., \\\"2021-09\\\")\\n            yield year_month, 1\\n\\n    def reducer(self, year_month, counts):\\n        total_reviews = sum(counts)\\n        yield year_month, total_reviews\\n\\nif __name__ == '__main__':\\n    count_of_review_yearmonth.run()\\n\"\n",
      "        },\n",
      "        {\n",
      "            \"type\": \"code\",\n",
      "            \"content\": \"import count_of_review_yearmonth\\nmr_job = count_of_review_yearmonth.count_of_review_yearmonth(args=['yelp_2.csv'])\\nwith mr_job.make_runner() as runner:\\n    runner.run()\\n    for key, value in mr_job.parse_output(runner.cat_output()):\\n        print(key,value)\"\n",
      "        },\n",
      "        {\n",
      "            \"type\": \"code\",\n",
      "            \"content\": \"#3.Average rating of any review marked \\u201dcool\\u201d (eg where cool != 0)\\n\"\n",
      "        },\n",
      "        {\n",
      "            \"type\": \"code\",\n",
      "            \"content\": \"%%file Average_rating_forcool.py\\nfrom mrjob.job import MRJob\\nimport csv\\n\\nclass Average_rating_forcool(MRJob):\\n\\n    def mapper(self, _, line):\\n        fields = next(csv.reader([line]))\\n        if len(fields) >= 10:\\n            cool, stars = fields[8], fields[4]\\n            \\n            # Check if 'cool' is not zero and 'stars' is not the header\\n            if cool != '0' and stars != 'stars':\\n                yield None, float(stars)\\n\\n    def reducer(self, _, stars):\\n        list_stars = list(stars)\\n        if list_stars:\\n            average_star_rating = sum(list_stars) / len(list_stars)\\n            yield \\\"Average rating of any review marked cool \\\", average_star_rating\\n\\nif __name__ == '__main__':\\n    Average_rating_forcool.run()\\n\"\n",
      "        },\n",
      "        {\n",
      "            \"type\": \"code\",\n",
      "            \"content\": \"import Average_rating_forcool\\nmr_job = Average_rating_forcool.Average_rating_forcool(args=['yelp_2.csv'])\\nwith mr_job.make_runner() as runner:\\n    runner.run()\\n    for key, value in mr_job.parse_output(runner.cat_output()):\\n        print(\\\"Average rating of any review marked cool is \\\",value)\"\n",
      "        },\n",
      "        {\n",
      "            \"type\": \"code\",\n",
      "            \"content\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "AI: Grade:85, summarized Feedback: Question 1 will not execute, Possible Errors: Incorrect class name is used while invoking\n"
     ]
    }
   ],
   "source": [
    "print(few_shot_prompt.format())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Few shot without context(Rubic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grade: 70\n",
      "\n",
      "Feedback:\n",
      "\n",
      "- The code is well-structured and easy to read.\n",
      "- The use of pandas for data manipulation is appropriate and efficient.\n",
      "- The logic used to solve the problems is correct and the code produces the expected results.\n",
      "- However, the code is not scalable. It works well for small datasets but for larger datasets, it would be more efficient to use a map-reduce framework like Hadoop or Spark.\n",
      "- The code could be improved by adding more comments to explain the logic and the steps.\n",
      "- The code could also be improved by defining functions for repeated code blocks.\n",
      "- The code does not handle exceptions or errors. It would be better to add error handling to make the code more robust.\n",
      "- The code does not have any unit tests. It would be better to add tests to ensure the code works as expected.\n"
     ]
    }
   ],
   "source": [
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant that evaluate python program and grad from 1-100 and \\\n",
    "         explain why you gave such grade. make sure to provide your response in bullet points\"),\n",
    "        few_shot_prompt,\n",
    "        (\"user\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "chain = final_prompt | chat\n",
    "response_without_context = chain.invoke({\"input\": formatted_data})\n",
    "points = response_without_context.content.split(\"\\n\")\n",
    "for point in points:\n",
    "    print(f\"{point}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### few shot with context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grade: 20, summarized Feedback: No map/reduce logic has been written to do the task. DataFrames are not allowed\n"
     ]
    }
   ],
   "source": [
    "Instruction = \"\"\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant that evaluate python program and grad from 1-100 and explain why you gave such grade. make sure to provide your response in bullet points\\\n",
    "         \" + Instruction\n",
    "),\n",
    "        few_shot_prompt,\n",
    "        (\"user\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "chain = final_prompt | chat\n",
    "response_without_context = chain.invoke({\"input\": formatted_data})\n",
    "points = response_without_context.content.split(\"\\n\")\n",
    "for point in points:\n",
    "    print(f\"{point}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        So, I have inferenced a gpt-4 model to identify best prompting way to get the desired results on Evaluating student assignments. \n",
    "\n",
    "        Hence performing few-shot prompting has showed significant improvement but still the model focused more coding standards.\n",
    "\n",
    "        To improve further, provided content on what the model shoud be looking for in grading the assignments. With that I was able to achieve the desired output. \n",
    "\n",
    "        Using this Prompt with context(Instruction) for Fine Tuning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
